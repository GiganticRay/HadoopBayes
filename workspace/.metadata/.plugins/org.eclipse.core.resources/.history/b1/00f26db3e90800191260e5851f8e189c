import java.io.IOException;
import java.math.BigDecimal;
import java.net.URI;
import java.util.HashMap;
import java.util.Map;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;

// attention: 因为用户的评论里面可能也会有 "好评" "差评" 的字样、所以定义 IsPraise 为 "好评" "IsNotPraise" 为 "差评"
public class BayesClassfier
{
	// region: 全局变量设置区
	public static Map<String, Integer> featureFrequency = new HashMap<String, Integer>();
	public static int preciseCount = 0;						// 当前准确条数
	public static Configuration conf = new Configuration();	// 也可用 set 方法重新设置（会覆盖）: conf.set("fs.default.name", //"hdfs"//xxxx:9000) Configuration 类： 创建时会 | 读取 Hadoop 的配置文件，如 site-core.xml...;
	// endregion
	public static class TokenizerMapper extends Mapper<Object, Text, Text, IntWritable>{
		
		private final static IntWritable one = new IntWritable(1);
		private Text word = new Text();
		
		// value: 每一行的内容
		public void map(Object key, Text value, Context context) throws IOException, InterruptedException{	
			String IsPraise = new String();	// define a signal of IsPraise or IsNotPraise

			StringTokenizer itr = new StringTokenizer(value.toString());
			// IsPraise or not, 处理位于每一行第一个词的 label
			if(itr.hasMoreTokens()){
				IsPraise = itr.nextToken().toString();	// 获取第一个label
				IsPraise = (IsPraise.equals("好评")) ?  "IsPraise" : "IsNotPraise";
				word.set("IsPraise" + IsPraise);
				context.write(word, one);
			}
			while(itr.hasMoreTokens())
			{	
				word.set(itr.nextToken() + IsPraise);
				context.write(word, one);
			}
		}
		
	}
	
	public static class IntSumReducer extends Reducer<Text, IntWritable, Text, IntWritable>{
		private IntWritable result = new IntWritable();
		
		public void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException{
			int sum = 0;
			for (IntWritable val : values)
			{
				sum += val.get();
			}
			
			result.set(sum);
			context.write(key, result);
		}
	}
	
	// 初始化每个单词频数到 featureFrequency 的全局变量
	public static class BayesInitMapper extends Mapper<Object, Text, Text, IntWritable>{
		private final static IntWritable one = new IntWritable(1);
		private Text word = new Text();
		
		// value: 每一行的内容, 这里遍历的就是每一个变量的频数，把他们存到全局变量里面去
		public void map(Object key, Text value, Context context) throws IOException, InterruptedException{	
			StringTokenizer itr = new StringTokenizer(value.toString());
			String[] lineContent = value.toString().split("\t");
			BayesClassfier.featureFrequency.put(lineContent[0], Integer.parseInt(lineContent[1]));	// 将其频数存放于全局变量
		}
	}
	
	// 预测的 mapper
	public static class BayesPredictMapper extends Mapper<Object, Text, Text, IntWritable>{
		private final static IntWritable one = new IntWritable(1);
		private Text word = new Text();
		
		// value: 每一行的内容
		public void map(Object key, Text value, Context context) throws IOException, InterruptedException{	
			String IsPraise = new String();	// define a signal of IsPraise or IsNotPraise
			
			// 统计数量
			Double AllIsPraiseCount = 1.0 * BayesClassfier.featureFrequency.get("IsPraiseIsPraise");
			Double AllIsNotPraiseCount = 1.0 * BayesClassfier.featureFrequency.get("IsPraiseIsNotPraise");
			Double AllCount = AllIsPraiseCount + AllIsNotPraiseCount;
			
			// 应用贝叶斯公式、详见文档
			Double IsPraiseProb = 1.0 * (AllIsPraiseCount/AllCount);
			Double IsNotPraiseProb = 1.0 * (AllIsNotPraiseCount/AllCount);
			BigDecimal adecimal = new BigDecimal(IsPraiseProb);
			BigDecimal bdecimal = new BigDecimal(IsNotPraiseProb);
			
			// 本条记录的好坏
			String IsThisPraise = "";
						
			StringTokenizer itr = new StringTokenizer(value.toString());
			if(itr.hasMoreTokens()){
				// 先获取本条记录的好坏
				IsThisPraise = (itr.nextToken().equals("好评")) ? "好评" : "差评";
			}
			
			while(itr.hasMoreTokens())
			{
				String itrWord = itr.nextToken();
				// 平滑处理、如果没有这个值就给他 1
				Double itrWordIsPraiseCount = 1.0 * ((BayesClassfier.featureFrequency.containsKey((itrWord + "IsPraise"))) ? BayesClassfier.featureFrequency.get(itrWord + "IsPraise") : 1);
				Double itrWordIsNotPraiseCount = 1.0 * ((BayesClassfier.featureFrequency.containsKey((itrWord + "IsNotPraise"))) ? BayesClassfier.featureFrequency.get(itrWord + "IsNotPraise") : 1);
				
				IsPraiseProb *=  itrWordIsPraiseCount / AllIsPraiseCount;
				IsNotPraiseProb *= itrWordIsNotPraiseCount / AllIsNotPraiseCount;
			}
			IsPraise = (IsPraiseProb > IsNotPraiseProb) ? "好评" : "差评";
			// 说明预测准确
//			if(IsThisPraise.equals(IsPraise) && IsThisPraise.equals("好评")){
			if(IsThisPraise.equals(IsPraise)){
				BayesClassfier.preciseCount++;
			}
			word.set(value.toString() + "\t" + IsPraise);
			context.write(word, one);
		}
	}
	
	public static class BayesPredict{
		// 初始化全局参数
		public static void InitGlobalPara(){
			BayesClassfier.preciseCount = 0;	// 归零
		}
		
		// 训练, 得到统计频数文件
		public static void GetFrequencyFile(String[] otherArgs) throws Exception{
			Job trainJob = new Job(conf, "word count2");	// 新建一个 Job，传入配置信息	JobTrack 和 TaskTrack 都是 MRv1 用的东西了
			// region
//			trainJob.setJar("wordcount2.jar");			// 设置运行的jar文件
			// endregion
			trainJob.setJarByClass(wordcount2.class);		// 设置主类
			trainJob.setMapperClass(TokenizerMapper.class);	// 设置 Mapper 类
			trainJob.setCombinerClass(IntSumReducer.class);	// 设置作业合成类	(就是在 map 之后、reduce 之前、要进行一次)
			trainJob.setReducerClass(IntSumReducer.class);	// 设置 Reducer 类
			trainJob.setOutputKeyClass(Text.class);			// 设置输出数据的关键类
			trainJob.setOutputValueClass(IntWritable.class);	// 设置输出值类
			
			// Train model, 就是统计每一个 特征属性 好评、差评 的频率
			FileInputFormat.addInputPath(trainJob, new Path(otherArgs[0]));	// 文件输入
			FileOutputFormat.setOutputPath(trainJob, new Path(otherArgs[1]));// 文件输出
			
			boolean flag = trainJob.waitForCompletion(true);
			System.out.print("SUCCEED!" + flag);
		}
		
		// 初始化 全局变量 map frequency
		public static void InitFrequencyMap() throws Exception{
			// countFrequencyJob: 判断输入文件中每一行的值
			Job countFrequencyJob = new Job(conf, "countFrequencyJob");
//			countFrequencyJob.setJar("wordcount2.jar");
			countFrequencyJob.setMapperClass(BayesInitMapper.class);	// 设置 Mapper 类
			countFrequencyJob.setNumReduceTasks(0);   	 			//reduce的数量设为0
			
			FileInputFormat.addInputPath(countFrequencyJob, new Path("hdfs://192.168.10.100:9000/user/Hadoop/eclipseOutput2/part-r-00000"));	// 文件输入
			FileOutputFormat.setOutputPath(countFrequencyJob, new Path("hdfs://192.168.10.100:9000/user/Hadoop/eclipseOutput3"));// 文件输出
			boolean flag = countFrequencyJob.waitForCompletion(true);
			System.out.println("InitFrequencyMap SUCCEED!" + flag);
			
			// 删除输出的文件夹、没有找到不产生输出文件的方法...
			FileSystem fileSystem = FileSystem.get(new URI("hdfs://192.168.10.100:9000"), conf);
			if (fileSystem.exists(new Path("/user/Hadoop/eclipseOutput3"))) {
				fileSystem.delete(new Path("/user/Hadoop/eclipseOutput3"), true);
				System.out.println("delete output file SUCCEED!");
			}
		}
		
		// 预测文件
		public static void Predict() throws Exception{
			// 写一个 Predict Map、在定义一个job3, 读取每一行、然后分别算出 好评/差评的概率来比较、最终输出到文件
			// countFrequencyJob: 判断输入文件中每一行的值
			Job predictJob = new Job(conf, "countFrequencyJob");
//			predictJob.setJar("wordcount2.jar");
			predictJob.setMapperClass(BayesPredictMapper.class);	// 设置 Mapper 类
			predictJob.setNumReduceTasks(0);   	 			//reduce的数量设为0
			
			FileInputFormat.addInputPath(predictJob, new Path("hdfs://192.168.10.100:9000/user/Hadoop/BayesData/test-1000.txt"));	// 文件输入
			FileOutputFormat.setOutputPath(predictJob, new Path("hdfs://192.168.10.100:9000/user/Hadoop/eclipseOutput4"));// 文件输出
			boolean flag = predictJob.waitForCompletion(true);
			System.out.println("GetFrequencyMap SUCCEED!" + flag);
			
			// 删除输出的文件夹、没有找到不产生输出文件的方法...
//			FileSystem fileSystem = FileSystem.get(new URI("hdfs://192.168.10.100:9000"), conf);
//			if (fileSystem.exists(new Path("/user/Hadoop/eclipseOutput4"))) {
//				fileSystem.delete(new Path("/user/Hadoop/eclipseOutput4"), true);
//				System.out.println("delete output file SUCCEED!");
//			}
		}	
	}
	
	// 主函数
	public static void main(String[] args) throws Exception
	{
		String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();	// 将命令行中参数自动设置到变量 conf 中
		// region 以下为 eclopse 插件提交所添加的代码、因为之前配置的hadoopLocation 并没有完全起作用、eclipse 获取不到集群环境下的配置信息，导致提交任务是加载的配置信息为默认值
		conf.set("fs.defaultFS", "hdfs://192.168.10.100:9000");
		conf.set("hadoop.job.user", "ray");
		conf.set("mapreduce.jobtracker.address", "192.168.10.100:9001");
		conf.set("yarn.resourcemanager.hostname", "192.168.10.100");
		conf.set("yarn.resourcemanager.admin.address", "192.168.10.100:8033");
		conf.set("yarn.resourcemanager.address", "192.168.10.100:8032");
		conf.set("yarn.resourcemanager.scheduler.address", "192.168.10.100:8030");
		// endregion
		
		if(otherArgs.length != 2){
			System.err.println("Usage: wordcount <in><out>");
			System.exit(2);
		}
		
		BayesPredict.InitGlobalPara();		// 初始化频数全局变量
		// BayesPredict.GetFrequencyFile(args);	// 训练, 得到频数文件 eclipseOutput2
		BayesPredict.InitFrequencyMap();	// 得到频数 Global Para
		BayesPredict.Predict();				// 预测文件、并输出		输出到 eclipseOutput4
		System.out.println();
		
		
		
		
		System.out.println(BayesClassfier.preciseCount / 2000.0);
	}

}
